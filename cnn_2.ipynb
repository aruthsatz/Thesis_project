{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c29d3f6c-05df-45f1-b7ed-1e68888d14d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2b10ca4-bf77-47de-8e84-5857d23c6802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "333da8f6-d52c-4e87-b035-72b90638a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "#np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc67f1cb-33fd-435c-ba0d-0481ab82cfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "X_train = Path.cwd() / 'train'\n",
    "X_test = Path.cwd() / 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bfb38f4-256a-4b67-99f6-f24f6ae5f24f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# THIS LOOP GRABS EACH FILE IN TRAIN DIRECTORY, LOADS IT INTO NUMPY, STANDARDIZES IT, AND THEN APPENDS IT TO AN EMPTY LIST\n",
    "# WHAT IS RETURNED IS A TENSOR WITH SHAPE (3637, 80, 64)\n",
    "\n",
    "train_data = []\n",
    "counter = 0\n",
    "for train_class in os.listdir(train_dir):\n",
    "    for d in os.listdir(os.path.join(train_dir, train_class)):\n",
    "        d_path = os.path.join(train_dir, train_class, d)\n",
    "       # print('\\n\\n', d_path)\n",
    "        counter += 1\n",
    "        #print(f'{counter} / 3637')\n",
    "        \n",
    "                #IMPORTING DATA \n",
    "        np_train_data = np.genfromtxt(d_path, delimiter=\",\", skip_header=1)\n",
    "        \n",
    "                #DELETING INDEX COLUMN\n",
    "        np_train_data = np.delete(np_train_data, 0, axis=1)\n",
    "        \n",
    "                #SCALING THE DATA FOR MACHINE LEARNING\n",
    "        m1 = np.min(np_train_data, axis=0)\n",
    "        m2 = np.max(np_train_data, axis=0)\n",
    "        np_train_data_std = (np_train_data - m1) / (m2 - m1)\n",
    "        \n",
    "            \n",
    "        #mean = np.mean(np_train_data, axis=0)\n",
    "        #std = np.std(np_train_data, axis=0)\n",
    "        #np_train_data_std = (np_train_data - mean) / std\n",
    "        \n",
    "        \n",
    "        \n",
    "        train_data.append(np_train_data_std)\n",
    "train_data = tf.stack(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c26dcc4-fb12-4da1-836a-22bf5815dd4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = []\n",
    "counter = 0\n",
    "for test_class in os.listdir(test_dir):\n",
    "    for d in os.listdir(os.path.join(test_dir, test_class)):\n",
    "        d_path = os.path.join(test_dir, test_class, d)\n",
    "        #print('\\n\\n', d_path)\n",
    "        counter += 1\n",
    "        #print(f'{counter} / 1320')\n",
    "        \n",
    "                #IMPORTING DATA \n",
    "        np_test_data = np.genfromtxt(d_path, delimiter=\",\", skip_header=1)\n",
    "        \n",
    "                #DELETING INDEX COLUMN\n",
    "        np_test_data = np.delete(np_test_data, 0, axis=1)\n",
    "        np_test_data = np.delete(np_test_data, [-3], axis=1)\n",
    "                #SCALING THE DATA FOR MACHINE LEARNING\n",
    "        m1 = np.min(np_test_data, axis=0)\n",
    "        m2 = np.max(np_test_data, axis=0)\n",
    "        np_test_data_std = (np_test_data - m1) / (m2 - m1)\n",
    "            \n",
    "        #mean = np.mean(np_test_data, axis=0)\n",
    "        #std = np.std(np_test_data, axis=0)\n",
    "        #np_test_data_std = (np_test_data - mean) / std\n",
    "        \n",
    "        \n",
    "        \n",
    "        test_data.append(np_test_data_std)\n",
    "test_data = tf.stack(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "befc2bfe-e0ab-4b50-97ad-2b7c5768c272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1320, 80, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2424ef34-758e-4660-a115-c10a2ff589da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3637, 80, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a867190-f2f1-40af-a917-79fb3b7bf492",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "                #TEST PANDAS DF\n",
    "\n",
    "#print(pd_train_data.head(), '\\n\\n')\n",
    "#print(f'pd_train_data datatype------------------------------------ \\n\\n\\t{type(pd_train_data)}')\n",
    "\n",
    "                #TEST LIST OF PANDAS DF\n",
    "\n",
    "#list_train = [pd_train_data]\n",
    "#print(f'\\nlength of list_train: ------------------------------------\\n\\n\\t{len(list_train)}')\n",
    "#print(f'\\nlist of train data: \\n\\n{list_train}')\n",
    "\n",
    "                #TEST NUMPY ARRAY\n",
    "\n",
    "np_train_data = np.delete(np_train_data, 0, axis=1)\n",
    "print('\\n\\n numpy.ndarray -------------------------------------------- \\n\\n\\t', np_train_data)\n",
    "print('\\n\\n   datatype: \\n\\n\\t', type(np_train_data))\n",
    "\n",
    "                #TEST CONVERTING NUMPY ARRAY TO TENSOR\n",
    "\n",
    "tf_train_data = tf.convert_to_tensor(np_train_data)\n",
    "print('\\n\\ntensor of tf_train_data: \\n\\n\\t', tf_train_data)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4ff884-c7c4-4dee-806c-971ea0bc8f2e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "np_train_data2 = np.genfromtxt('train/away_wins/ATL_BRK_2019_12_04.csv', delimiter=\",\", skip_header=1)\n",
    "np_train_data2 = np.delete(np_train_data2, 0, axis=1)\n",
    "print('\\n\\n numpy.ndarray -------------------------------------------- \\n\\n\\t', np_train_data2)\n",
    "print('\\n\\n   datatype: \\n\\n\\t', type(np_train_data2))\n",
    "\n",
    "                #TEST CONVERTING NUMPY ARRAY TO TENSOR\n",
    "\n",
    "tf_train_data2 = tf.convert_to_tensor(np_train_data2)\n",
    "print('\\n\\ntensor of tf_train_data2: \\n\\n\\t', tf_train_data2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60af1f06-8206-4099-8f06-3aacb186ca99",
   "metadata": {},
   "source": [
    "## Y_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8c344b0-25af-4619-9911-76a33312822b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "away_wins directory: 1647\n",
      "home_wins directory: 1990\n",
      "total games: 3637\n"
     ]
    }
   ],
   "source": [
    "away_wins = os.listdir('train/away_wins')\n",
    "print('away_wins directory:', len(away_wins))\n",
    "home_wins = os.listdir('train/home_wins')\n",
    "print('home_wins directory:', len(home_wins))\n",
    "print('total games:', len(away_wins + home_wins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "806bb129-a9f6-4b83-a753-1525efcf549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test1 = []\n",
    "for a in range(0,1647):\n",
    "    y_test1.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8303d97f-917c-4613-8359-09025afba99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2 = []\n",
    "for h in range(0,1990):\n",
    "    y_test2.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbed8217-a07e-47b5-8402-a4c609cb5eea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3637"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test3 = list(y_test1 + y_test2)\n",
    "len(y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "034125db-7770-445f-9dad-2426e6a1c06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.convert_to_tensor(\n",
    "    y_test3, dtype=tf.float64, dtype_hint=None, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc514359-c681-44ce-b915-e103ecf8241d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d80043-fa4e-4b6f-9a98-121875ab7a34",
   "metadata": {},
   "source": [
    "## Y_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ee7b633-f185-43da-ae35-7a0e8b76b5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "away_wins directory: 553\n",
      "home_wins directory: 767\n",
      "total games: 1320\n"
     ]
    }
   ],
   "source": [
    "away_wins = os.listdir('test/away_wins')\n",
    "print('away_wins directory:', len(away_wins))\n",
    "home_wins = os.listdir('test/home_wins')\n",
    "print('home_wins directory:', len(home_wins))\n",
    "print('total games:', len(away_wins + home_wins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42d2a5bd-81ce-4baf-ae5b-0ebe99181ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test01 = []\n",
    "for a in range(0,553):\n",
    "    y_test01.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "494fe76c-9b49-43d2-b638-e41dd375c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test02 = []\n",
    "for h in range(0,767):\n",
    "    y_test02.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a506a50b-4146-4f3f-bc2f-f896f63946c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1320"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test03 = list(y_test01 + y_test02)\n",
    "len(y_test03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d0b28dd-5904-425d-8931-95443b535e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = tf.convert_to_tensor(\n",
    "    y_test03, dtype=tf.float64, dtype_hint=None, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c68fa5e-10cf-4919-867e-c19eff9cc789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017cc45d-ed23-411c-819a-21738ab1942a",
   "metadata": {},
   "source": [
    "## BUILDING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4678184-80df-42a8-a3c6-6642001efde3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# np.isnan(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9dbc70-d69c-4f8f-8ebe-39c3bb75393b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2d809ad-c7c7-4c7b-85d8-2a24914ed5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3637, 80, 64)\n",
      "(3637,)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(y_train.shape)\n",
    "print(type(y_train))\n",
    "print(type(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a6db5d5-44f2-4bbf-b63e-cbaacfdb0d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_height = 80\n",
    "array_width = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a7d3fcaa-7c61-456d-b848-77f919654ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  layers.Rescaling(1, input_shape=(array_height, array_width, 1)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a963af81-c8d8-4223-af51-6b5856c7bcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_1 (Rescaling)     (None, 80, 64, 1)         0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 80, 64, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 40, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 40, 32, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 20, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 20, 16, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 10, 8, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 5120)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               655488    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 679,042\n",
      "Trainable params: 679,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76d58fb5-6cd0-4491-8e41-417bb6734536",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef477dc6-27c2-47f6-8849-9a20f8747ea5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "114/114 [==============================] - 24s 190ms/step - loss: nan - accuracy: 0.4528 - val_loss: nan - val_accuracy: 0.4189\n",
      "Epoch 2/10\n",
      "114/114 [==============================] - 20s 179ms/step - loss: nan - accuracy: 0.4528 - val_loss: nan - val_accuracy: 0.4189\n",
      "Epoch 3/10\n",
      "114/114 [==============================] - 21s 184ms/step - loss: nan - accuracy: 0.4528 - val_loss: nan - val_accuracy: 0.4189\n",
      "Epoch 4/10\n",
      "114/114 [==============================] - 21s 184ms/step - loss: nan - accuracy: 0.4528 - val_loss: nan - val_accuracy: 0.4189\n",
      "Epoch 5/10\n",
      "114/114 [==============================] - 22s 192ms/step - loss: nan - accuracy: 0.4528 - val_loss: nan - val_accuracy: 0.4189\n",
      "Epoch 6/10\n",
      "114/114 [==============================] - 21s 184ms/step - loss: nan - accuracy: 0.4528 - val_loss: nan - val_accuracy: 0.4189\n",
      "Epoch 7/10\n",
      "114/114 [==============================] - 21619s 191s/step - loss: nan - accuracy: 0.4528 - val_loss: nan - val_accuracy: 0.4189\n",
      "Epoch 8/10\n",
      "114/114 [==============================] - 147234s 1303s/step - loss: nan - accuracy: 0.4528 - val_loss: nan - val_accuracy: 0.4189\n",
      "Epoch 9/10\n",
      "114/114 [==============================] - 22s 190ms/step - loss: nan - accuracy: 0.4528 - val_loss: nan - val_accuracy: 0.4189\n",
      "Epoch 10/10\n",
      "114/114 [==============================] - 15s 132ms/step - loss: nan - accuracy: 0.4528 - val_loss: nan - val_accuracy: 0.4189\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "history = model.fit(\n",
    "  train_data,\n",
    "    y_train,\n",
    "    validation_data=(test_data, y_test),\n",
    "    batch_size=32,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8849a24-d184-4d13-a99a-3e240f3c1ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1361dc37-9782-4baa-bf14-915f58cc4e91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48a16ab8-efe0-4594-8e41-d45a6e35343d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       " 'accuracy': [0.4528457522392273,\n",
       "  0.4528457522392273,\n",
       "  0.4528457522392273,\n",
       "  0.4528457522392273,\n",
       "  0.4528457522392273,\n",
       "  0.4528457522392273,\n",
       "  0.4528457522392273,\n",
       "  0.4528457522392273,\n",
       "  0.4528457522392273,\n",
       "  0.4528457522392273],\n",
       " 'val_loss': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       " 'val_accuracy': [0.41893938183784485,\n",
       "  0.41893938183784485,\n",
       "  0.41893938183784485,\n",
       "  0.41893938183784485,\n",
       "  0.41893938183784485,\n",
       "  0.41893938183784485,\n",
       "  0.41893938183784485,\n",
       "  0.41893938183784485,\n",
       "  0.41893938183784485,\n",
       "  0.41893938183784485]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e107eca-d30f-4182-b6b6-2b2be849d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4bfae5-8efa-4edc-b5d3-f097d552735a",
   "metadata": {},
   "source": [
    "# TESTING USING CONV1D LAYER INSTEAD OF CONV2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a160d6b2-887e-43ec-b8fc-5e7ed4d09216",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(y_train.shape)\n",
    "print(type(y_train))\n",
    "print(type(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c687926-a55b-4f63-af5b-88de90ab4a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57287d71-6efb-45ce-87cd-4ee53b6f4e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (3637,80,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b5cc68-ffec-46ac-b9c8-37500197a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv1D(64, 2, activation=\"relu\", input_shape=(80,64)))\n",
    "model2.add(Dense(16, activation=\"relu\"))\n",
    "model2.add(MaxPooling1D())\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(3, activation = 'softmax'))\n",
    "model2.compile(loss = 'sparse_categorical_crossentropy', \n",
    "     optimizer = \"adam\",               \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03facf4d-90d5-4910-b6fe-284a9aa337f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b083b-89b7-4014-9eea-fcd9894acac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs=10\n",
    "history = model2.fit(\n",
    "  train_data,\n",
    "    y_train,\n",
    "  epochs=epochs\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
